{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ktsDB3QpJdX",
        "outputId": "05cd89d8-51e5-495e-ea07-5b3cb293b013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Mon Oct 27 12:56:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS65GtBHjH-2",
        "outputId": "6fbb7e40-0bf8-4d8d-b66f-f8974a7e6fb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile validate_mpgguf.cu\n",
        "\n",
        "// mpgguf_validate.cu  — MPGGUF v2 validator with hardened GGUF/MP readers\n",
        "//\n",
        "// Build:\n",
        "//   nvcc -O3 -std=c++17 -o mpgguf_validate mpgguf_validate.cu\n",
        "//\n",
        "// Usage:\n",
        "//   ./mpgguf_validate --mpgguf model.mpgguf --fp16 baseline_f16_or_f32.gguf [--report] [--diff-high-low]\n",
        "//\n",
        "// What it does:\n",
        "//   * Loads MPGGUF v2 container (LOW/HIGH/FP slots, adjacent packing).\n",
        "//   * Loads baseline GGUF (FP16 or FP32 weights) using a tolerant KV skipper and safe strings.\n",
        "//   * Dequantizes HIGH (Q8_0) and legacy scalar 2-bit LOW when recognizable by size.\n",
        "//   * Computes MSE, RMSE, and max|Δ| vs FP16 baseline (and optional HIGH vs LOW).\n",
        "//   * Skips unknown 2-bit layouts (e.g., Q2_K / IQ2_XXS) with a clear notice.\n",
        "//\n",
        "// Notes:\n",
        "//   * No inference — this only validates dequantized weights vs a baseline.\n",
        "//   * All readers are fast-fail hardened to avoid endless parsing on malformed files.\n",
        "\n",
        "#include <cuda_fp16.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdint.h>\n",
        "\n",
        "#include <algorithm>\n",
        "#include <cmath>\n",
        "#include <cstring>\n",
        "#include <fstream>\n",
        "#include <iostream>\n",
        "#include <sstream>\n",
        "#include <string>\n",
        "#include <unordered_map>\n",
        "#include <vector>\n",
        "\n",
        "// ------------- CUDA helpers -------------\n",
        "#define CUDA_OK(x)                                                                                          \\\n",
        "    do {                                                                                                    \\\n",
        "        auto _e = (x);                                                                                      \\\n",
        "        if (_e != cudaSuccess) {                                                                            \\\n",
        "            std::cerr << \"CUDA \" << cudaGetErrorString(_e) << \" @ \" << __FILE__ << \":\" << __LINE__ << \"\\n\"; \\\n",
        "            std::exit(1);                                                                                   \\\n",
        "        }                                                                                                   \\\n",
        "    } while (0)\n",
        "\n",
        "#ifndef QK\n",
        "#    define QK 32  // scalar block size used by Q8_0 and the legacy 2-bit variants\n",
        "#endif\n",
        "\n",
        "static inline bool aligned32(uint64_t x) {\n",
        "    return (x & 31ull) == 0ull;\n",
        "}\n",
        "\n",
        "static inline bool aligned64(uint64_t x) {\n",
        "    return (x & 63ull) == 0ull;\n",
        "}\n",
        "\n",
        "\n",
        "static std::vector<uint8_t> readStreamData(std::ifstream& f, size_t sz, size_t offset) {\n",
        "    std::vector<uint8_t> out;\n",
        "\n",
        "    if (!f.good()) return out;\n",
        "\n",
        "    // 1) Clear any eof/fail from prior ops; required before seekg on some FUSE filesystems.\n",
        "    f.clear();\n",
        "\n",
        "    // 2) Find file size.\n",
        "    std::istream::pos_type cur = f.tellg();\n",
        "    f.seekg(0, std::ios::end);\n",
        "    std::istream::pos_type end = f.tellg();\n",
        "    if (end <= 0) { f.clear(); return out; }\n",
        "    const size_t file_size = static_cast<size_t>(end);\n",
        "\n",
        "    // 3) Validate and clamp request.\n",
        "    if (offset >= file_size) { f.clear(); return out; }\n",
        "    const size_t to_read = std::min(sz, file_size - offset);\n",
        "\n",
        "    // 4) Seek to absolute offset from beginning.\n",
        "    f.clear(); // (again, in case tellg/setg flipped eof)\n",
        "    f.seekg(static_cast<std::streamoff>(offset), std::ios::beg);\n",
        "    if (!f.good()) { f.clear(); return out; }\n",
        "\n",
        "    // 5) Read with partial-read handling.\n",
        "    out.resize(to_read);\n",
        "    f.read(reinterpret_cast<char*>(out.data()), static_cast<std::streamsize>(to_read));\n",
        "    const auto got = static_cast<size_t>(f.gcount());\n",
        "    if (got < to_read) {\n",
        "        out.resize(got);\n",
        "        // Reset state so later calls can still seek/read.\n",
        "        f.clear();\n",
        "    }\n",
        "    return out;\n",
        "}\n",
        "\n",
        "\n",
        "static uint64_t align_up(uint64_t off, uint32_t align)\n",
        "{\n",
        "    const uint64_t mask = static_cast<uint64_t>(align) - 1u;\n",
        "    return (off + mask) & ~mask;\n",
        "}\n",
        "\n",
        "static inline bool is_ascii_identifier(const std::string& s) {\n",
        "    if (s.empty() || s.size() > 512)\n",
        "        return false;\n",
        "\n",
        "    for (unsigned char c : s)\n",
        "    {\n",
        "        if (!((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') || c == '_' || c == '.' ||\n",
        "            c == '/' || c == '-')) {\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//=============== MPGGUF v2 reader ===============\n",
        "struct Rec\n",
        "{\n",
        "    std::string           name;\n",
        "    uint32_t              nd;\n",
        "    std::vector<uint64_t> dims;\n",
        "    uint32_t              flags, g_low, g_high, g_fp;\n",
        "    uint64_t              off_low, sz_low, off_high, sz_high, off_fp, sz_fp;\n",
        "};\n",
        "\n",
        "struct MP\n",
        "{\n",
        "    std::vector<Rec>     recs;\n",
        "    std::vector<uint8_t> kv;\n",
        "    std::ifstream        f;\n",
        "    size_t               data_offset;\n",
        "    size_t               data_sz;\n",
        "\n",
        "    bool Open(const std::string& path)\n",
        "    {\n",
        "        f.open(path, std::ios::binary);\n",
        "        if (!f.is_open()) {\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        return true;\n",
        "    }\n",
        "};\n",
        "\n",
        "static inline uint32_t rd_u32(const uint8_t* p)\n",
        "{\n",
        "    uint32_t v;\n",
        "    memcpy(&v, p, 4);\n",
        "    return v;\n",
        "}\n",
        "\n",
        "static inline uint64_t rd_u64(const uint8_t* p)\n",
        "{\n",
        "    uint64_t v;\n",
        "    memcpy(&v, p, 8);\n",
        "    return v;\n",
        "}\n",
        "\n",
        "static bool in_range(uint64_t off, uint64_t sz, size_t total)\n",
        "{\n",
        "    return off <= (uint64_t)total && sz <= (uint64_t)total && (off + sz) <= (uint64_t)total;\n",
        "}\n",
        "\n",
        "bool load_mp(const std::string& path, MP& out)\n",
        "{\n",
        "    if (out.Open(path) == false)\n",
        "        return false;\n",
        "\n",
        "    auto& f = out.f;\n",
        "\n",
        "    // Header\n",
        "    char mg[7];\n",
        "    f.read(mg, 7);\n",
        "    uint8_t ver = 0;\n",
        "    f.read((char*)&ver, 1);\n",
        "    if (std::string(mg, 7) != \"MPGGUF2\" || ver != 2) {\n",
        "        std::cerr << \"Not MPGGUF2 (\" << path << \")\\n\";\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    uint64_t kvsz = 0;\n",
        "    uint32_t nt = 0;\n",
        "    f.read((char*)&kvsz, 8);\n",
        "    f.read((char*)&nt, 4);\n",
        "\n",
        "    // Sanity cap on tensor count\n",
        "    const uint64_t kMaxT = 200000;\n",
        "    if (nt == 0 || nt > kMaxT)\n",
        "    {\n",
        "        std::cerr << \"ERROR: suspicious mpgguf n_t=\" << nt << \"\\n\";\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Directory\n",
        "    out.recs.reserve(nt);\n",
        "    const uint32_t kMaxName = 4096;\n",
        "    for (uint32_t i = 0; i < nt; i++)\n",
        "    {\n",
        "        uint32_t nl = 0;\n",
        "        f.read((char*)&nl, 4);\n",
        "        if (nl == 0 || nl > kMaxName)\n",
        "        {\n",
        "            std::cerr << \"ERROR: mpgguf name length \" << nl << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "        std::string name(nl, '\\0');\n",
        "        f.read(name.data(), nl);\n",
        "        if (!is_ascii_identifier(name))\n",
        "        {\n",
        "            std::cerr << \"ERROR: mpgguf bad name \" << name << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        uint32_t nd = 0;\n",
        "        f.read((char*)&nd, 4);\n",
        "        if (nd == 0 || nd > 6)\n",
        "        {\n",
        "            std::cerr << \"ERROR: mpgguf bad nd=\" << nd << \" for \" << name << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "        std::vector<uint64_t> dims(nd);\n",
        "        for (uint32_t d = 0; d < nd; ++d)\n",
        "        {\n",
        "            f.read((char*)&dims[d], 8);\n",
        "            if (dims[d] == 0 || dims[d] > (uint64_t) 1e10)\n",
        "            {\n",
        "                std::cerr << \"ERROR: mpgguf bad dim[\" << d << \"]=\" << dims[d] << \" for \" << name << \"\\n\";\n",
        "                return false;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        uint32_t flags = 0, gL = 0, gH = 0, gF = 0;\n",
        "        f.read((char*)&flags, 4);\n",
        "        f.read((char*)&gL, 4);\n",
        "        f.read((char*)&gH, 4);\n",
        "        f.read((char*)&gF, 4);\n",
        "        if ((flags & ~0x7u) != 0)\n",
        "        {\n",
        "            std::cerr << \"ERROR: mpgguf flags reserved bits set for \" << name << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        uint64_t oL = 0, sL = 0, oH = 0, sH = 0, oF = 0, sF = 0;\n",
        "        f.read((char*)&oL, 8);\n",
        "        f.read((char*)&sL, 8);\n",
        "        f.read((char*)&oH, 8);\n",
        "        f.read((char*)&sH, 8);\n",
        "        f.read((char*)&oF, 8);\n",
        "        f.read((char*)&sF, 8);\n",
        "\n",
        "        if (flags & 0x1)\n",
        "        {\n",
        "            if (!aligned64(oL))\n",
        "            {\n",
        "                std::cerr << \"ERROR: LOW off not 64B aligned\\n\";\n",
        "                return false;\n",
        "            }\n",
        "        }\n",
        "        if (flags & 0x2)\n",
        "        {\n",
        "            if (!aligned64(oH)) {\n",
        "                std::cerr << \"ERROR: HIGH off not 64B aligned\\n\";\n",
        "                return false;\n",
        "            }\n",
        "        }\n",
        "        if (flags & 0x4)\n",
        "        {\n",
        "            if (!aligned64(oF)) {\n",
        "                std::cerr << \"ERROR: FP off not 64B aligned\\n\";\n",
        "                return false;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        out.recs.push_back({ std::move(name), nd, std::move(dims), flags, gL, gH, gF, oL, sL, oH, sH, oF, sF });\n",
        "    }\n",
        "\n",
        "    // KV\n",
        "    out.kv.resize(kvsz);\n",
        "    if (kvsz)\n",
        "    {\n",
        "        f.read((char*)out.kv.data(), kvsz);\n",
        "    }\n",
        "\n",
        "    // Data region\n",
        "    // 1. Get the current position\n",
        "    std::streampos current_pos = f.tellg();\n",
        "    current_pos = align_up(current_pos, 64);\n",
        "\n",
        "    // 2. Seek to the end\n",
        "    f.seekg(0, std::ios::end);\n",
        "\n",
        "    // 3. Get the end position\n",
        "    std::streampos end_pos = f.tellg();\n",
        "\n",
        "    // 4. Calculate remaining size\n",
        "    std::streamsize remaining_size = end_pos - current_pos;\n",
        "\n",
        "    // 5. Seek back to the current position\n",
        "    f.seekg(current_pos);\n",
        "\n",
        "    out.data_offset = (size_t)current_pos;\n",
        "    out.data_sz = (size_t)remaining_size;\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// =============== GGUF (baseline) reader ===============\n",
        "enum\n",
        "{\n",
        "    GGUF_U8 = 0,\n",
        "    GGUF_I8 = 1,\n",
        "    GGUF_U16 = 2,\n",
        "    GGUF_I16 = 3,\n",
        "    GGUF_U32 = 4,\n",
        "    GGUF_I32 = 5,\n",
        "    GGUF_F32 = 6,\n",
        "    GGUF_BOOL = 7,\n",
        "    GGUF_STRING = 8,\n",
        "    GGUF_ARRAY = 9,\n",
        "    GGUF_U64 = 10,\n",
        "    GGUF_I64 = 11,\n",
        "    GGUF_F64 = 12,\n",
        "    GGUF_BYTES = 13\n",
        "};\n",
        "\n",
        "static int scalar_size(int t)\n",
        "{\n",
        "    switch (t) {\n",
        "    case GGUF_U8:\n",
        "    case GGUF_I8:\n",
        "    case GGUF_BOOL:\n",
        "        return 1;\n",
        "    case GGUF_U16:\n",
        "    case GGUF_I16:\n",
        "        return 2;\n",
        "    case GGUF_U32:\n",
        "    case GGUF_I32:\n",
        "    case GGUF_F32:\n",
        "        return 4;\n",
        "    case GGUF_U64:\n",
        "    case GGUF_I64:\n",
        "    case GGUF_F64:\n",
        "        return 8;\n",
        "    default:\n",
        "        return -1;\n",
        "    }\n",
        "}\n",
        "\n",
        "static std::string rd_s(std::istream& f)\n",
        "{\n",
        "    uint64_t n = 0;\n",
        "    f.read((char*)&n, 8);\n",
        "    const uint64_t kMaxStr = 4096 * 1024;  // cap for safety\n",
        "    if (n > kMaxStr) {\n",
        "        throw std::runtime_error(\"gguf string length over cap\");\n",
        "    }\n",
        "    std::string s((size_t)n, '\\0');\n",
        "    if (n) {\n",
        "        f.read(s.data(), (std::streamsize)n);\n",
        "    }\n",
        "    return s;\n",
        "}\n",
        "\n",
        "static void skip_bytes(std::istream& f)\n",
        "{\n",
        "    uint64_t n = 0;\n",
        "    f.read((char*)&n, 8);\n",
        "    f.seekg((std::streamoff)n, std::ios::cur);\n",
        "}\n",
        "\n",
        "static void skipv(std::istream& f)\n",
        "{\n",
        "    uint32_t t = 0;\n",
        "    f.read((char*)&t, 4);\n",
        "    int sz = scalar_size((int)t);\n",
        "    if (sz > 0) {\n",
        "        f.seekg(sz, std::ios::cur);\n",
        "        return;\n",
        "    }\n",
        "    if (t == GGUF_STRING) {\n",
        "        (void)rd_s(f);\n",
        "        return;\n",
        "    }\n",
        "    if (t == GGUF_BYTES) {\n",
        "        skip_bytes(f);\n",
        "        return;\n",
        "    }\n",
        "    if (t == GGUF_ARRAY) {\n",
        "        uint32_t et = 0;\n",
        "        uint64_t cnt = 0;\n",
        "        f.read((char*)&et, 4);\n",
        "        f.read((char*)&cnt, 8);\n",
        "        int es = scalar_size((int)et);\n",
        "        if (es > 0) {\n",
        "            f.seekg((std::streamoff)es * (std::streamoff)cnt, std::ios::cur);\n",
        "            return;\n",
        "        }\n",
        "        if (et == GGUF_STRING) {\n",
        "            for (uint64_t i = 0; i < cnt; i++) {\n",
        "                (void)rd_s(f);\n",
        "            }\n",
        "            return;\n",
        "        }\n",
        "        if (et == GGUF_BYTES) {\n",
        "            for (uint64_t i = 0; i < cnt; i++) {\n",
        "                skip_bytes(f);\n",
        "            }\n",
        "            return;\n",
        "        }\n",
        "        if (et == GGUF_ARRAY) {\n",
        "            for (uint64_t i = 0; i < cnt; i++) {\n",
        "                skipv(f);\n",
        "            }\n",
        "            return;\n",
        "        }\n",
        "        for (uint64_t i = 0; i < cnt; i++) {\n",
        "            skip_bytes(f);  // fallback\n",
        "        }\n",
        "        return;\n",
        "    }\n",
        "    skip_bytes(f);  // unknown top-level -> treat as BYTES\n",
        "}\n",
        "\n",
        "struct GRec\n",
        "{\n",
        "    size_t                splitId;\n",
        "    std::string           name;\n",
        "    uint32_t              nd;\n",
        "    std::vector<uint64_t> dims;\n",
        "    uint32_t              g;\n",
        "    uint64_t              off, sz;\n",
        "};\n",
        "\n",
        "struct GG\n",
        "{\n",
        "    std::vector<GRec>    recs;\n",
        "    std::ifstream f;\n",
        "\n",
        "    bool Open(const std::string& path)\n",
        "    {\n",
        "        f.open(path, std::ios::binary);\n",
        "        if (!f.is_open()) {\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        return true;\n",
        "    }\n",
        "};\n",
        "\n",
        "static size_t numel(const std::vector<uint64_t>& d)\n",
        "{\n",
        "    size_t n = 1;\n",
        "    for (auto v : d) {\n",
        "        n *= size_t(v);\n",
        "    }\n",
        "    return n;\n",
        "}\n",
        "\n",
        "bool load_fp(const size_t splitId, const std::string& path, GG& out)\n",
        "{\n",
        "    if (!out.Open(path))\n",
        "    {\n",
        "        std::cerr << \"open failed: \" << path << \"\\n\";\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    char mg[4];\n",
        "    out.f.read(mg, 4);\n",
        "    if (std::string(mg, 4) != \"GGUF\") {\n",
        "        std::cerr << \"not GGUF: \" << path << \"\\n\";\n",
        "        return false;\n",
        "    }\n",
        "    uint32_t ver = 0;\n",
        "    out.f.read((char*)&ver, 4);\n",
        "    uint64_t n_t = 0, n_kv = 0;\n",
        "    out.f.read((char*)&n_t, 8);\n",
        "    out.f.read((char*)&n_kv, 8);\n",
        "\n",
        "    const uint64_t kMaxKV = 200000, kMaxT = 200000;\n",
        "    if (n_kv == 0 || n_kv > kMaxKV) {\n",
        "        std::cerr << \"ERROR: suspicious n_kv=\" << n_kv << \"\\n\";\n",
        "        return false;\n",
        "    }\n",
        "    if (n_t == 0 || n_t > kMaxT) {\n",
        "        std::cerr << \"ERROR: suspicious n_t=\" << n_t << \"\\n\";\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Skip KV\n",
        "    try {\n",
        "        for (uint64_t i = 0; i < n_kv; i++) {\n",
        "            (void)rd_s(out.f);\n",
        "            skipv(out.f);\n",
        "        }\n",
        "    }\n",
        "    catch (const std::exception& e) {\n",
        "        std::cerr << \"WARN: KV skip failed: \" << e.what() << \", continuing\\n\";\n",
        "    }\n",
        "\n",
        "    // Tensor table\n",
        "    std::vector<GRec> recs;\n",
        "    recs.reserve((size_t)n_t);\n",
        "    for (uint64_t i = 0; i < n_t; i++) {\n",
        "        std::string name = rd_s(out.f);\n",
        "        if (!is_ascii_identifier(name)) {\n",
        "            std::cerr << \"ERROR: bad tensor name \" << name << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        uint32_t nd = 0;\n",
        "        out.f.read((char*)&nd, 4);\n",
        "        if (nd == 0 || nd > 6) {\n",
        "            std::cerr << \"ERROR: bad nd=\" << nd << \" for \" << name << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        std::vector<uint64_t> dims(nd);\n",
        "        for (uint32_t d = 0; d < nd; ++d) {\n",
        "            out.f.read((char*)&dims[d], 8);\n",
        "            if (dims[d] == 0 || dims[d] > (uint64_t) 1e10) {\n",
        "                std::cerr << \"ERROR: bad dim[\" << d << \"]=\" << dims[d] << \" for \" << name << \"\\n\";\n",
        "                return false;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        uint32_t g = 0;\n",
        "        out.f.read((char*)&g, 4);\n",
        "        uint64_t off = 0;\n",
        "        out.f.read((char*)&off, 8);\n",
        "        if (!aligned32(off)) {\n",
        "            std::cerr << \"ERROR: tensor data offset not 32B aligned for \" << name << \"\\n\";\n",
        "            return false;\n",
        "        }\n",
        "\n",
        "        recs.push_back({ splitId, std::move(name), nd, std::move(dims), g, off, 0 });\n",
        "    }\n",
        "\n",
        "    // 4) Remember the start of the data block\n",
        "    uint64_t data_block_start = static_cast<uint64_t>(out.f.tellg());\n",
        "    data_block_start = align_up(data_block_start, 32);\n",
        "\n",
        "    // Sizes by next off / EOF\n",
        "    out.f.seekg(0, std::ios::end);\n",
        "    size_t fsz = (size_t)out.f.tellg();\n",
        "\n",
        "    std::vector<GRec*> ord;\n",
        "    ord.reserve(recs.size());\n",
        "    for (auto& r : recs) {\n",
        "        ord.push_back(&r);\n",
        "    }\n",
        "    std::sort(ord.begin(), ord.end(), [](auto* a, auto* b) { return a->off < b->off; });\n",
        "    for (size_t i = 0; i < ord.size(); ++i) {\n",
        "        uint64_t nxt = (i + 1 < ord.size()) ? ord[i + 1]->off : (uint64_t)fsz;\n",
        "        if (nxt < ord[i]->off) {\n",
        "            std::cerr << \"ERROR: decreasing offsets in baseline\\n\";\n",
        "            return false;\n",
        "        }\n",
        "        ord[i]->sz = nxt - ord[i]->off;\n",
        "    }\n",
        "\n",
        "    for (auto& r : recs)\n",
        "        r.off += data_block_start;\n",
        "\n",
        "    // Whole file\n",
        "    out.recs = std::move(recs);\n",
        "    out.f.seekg(0, std::ios::beg);\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// =============== CUDA Dequant Kernels ===============\n",
        "// Q8_0: per 32 values: [float scale][int8 x 32]\n",
        "__global__ void k_deq_q8(const int8_t* q, const uint16_t* s, __half* out, int blocks) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id >= blocks) {\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    __half         h = __ushort_as_half(s[id]);\n",
        "    float          d = __half2float(h);\n",
        "\n",
        "    if (!isfinite(d))\n",
        "        d = 0.0f;\n",
        "\n",
        "    const int8_t* src = q + id * QK;\n",
        "    __half* dst = out + id * QK;\n",
        "#pragma unroll\n",
        "    for (int i = 0; i < QK; i++) {\n",
        "        dst[i] = __float2half(d * float(src[i]));\n",
        "    }\n",
        "}\n",
        "\n",
        "namespace q2k_detail {\n",
        "    static constexpr int    QK_K = 256;\n",
        "    static constexpr int    SCALES_SZ = QK_K / 16; // 16\n",
        "    static constexpr int    QS_SZ = QK_K / 4;  // 64\n",
        "    // CPU layout: [scales | qs | d(2) dmin(2)]\n",
        "    static constexpr int    BYTES_PER_BLOCK = SCALES_SZ + QS_SZ + 4; // 84\n",
        "\n",
        "    __device__ __forceinline__ uint16_t ld_u16_le(const uint8_t* p) {\n",
        "        return static_cast<uint16_t>(p[0]) | (static_cast<uint16_t>(p[1]) << 8);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel: writes __half\n",
        "__global__ void k_deq_q2_k_to_f16_scales_qs_tail(\n",
        "    const uint8_t* __restrict__ bytes,\n",
        "    __half* __restrict__ out,\n",
        "    size_t n_elems,\n",
        "    int    blocks)\n",
        "{\n",
        "    using namespace q2k_detail;\n",
        "\n",
        "    const int b = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (b >= blocks) return;\n",
        "\n",
        "    const size_t block_byte_off = static_cast<size_t>(b) * BYTES_PER_BLOCK;\n",
        "    const uint8_t* base_ptr = bytes + block_byte_off;\n",
        "\n",
        "    // [scales | qs | d(2) dmin(2)]\n",
        "    const uint8_t* scales = base_ptr;                 // 16 bytes\n",
        "    const uint8_t* qs = base_ptr + SCALES_SZ;     // 64 bytes\n",
        "    const uint8_t* tail = qs + QS_SZ;               // 4 bytes\n",
        "\n",
        "    const uint16_t d16 = q2k_detail::ld_u16_le(tail + 0);\n",
        "    const uint16_t dmin16 = q2k_detail::ld_u16_le(tail + 2);\n",
        "\n",
        "    const float d = __half2float(__ushort_as_half(d16));\n",
        "    const float dmin = __half2float(__ushort_as_half(dmin16));\n",
        "\n",
        "    const size_t out_base = static_cast<size_t>(b) * QK_K;\n",
        "    if (out_base >= n_elems) return;\n",
        "    const int block_elems = static_cast<int>(min(static_cast<size_t>(QK_K), n_elems - out_base));\n",
        "\n",
        "#pragma unroll\n",
        "    for (int g = 0; g < 16; ++g) {\n",
        "        const uint8_t s = scales[g];\n",
        "        const float dl = d * float(s & 0x0F);\n",
        "        const float ml = dmin * float(s >> 4);\n",
        "\n",
        "        const uint8_t b0 = qs[g * 4 + 0];\n",
        "        const uint8_t b1 = qs[g * 4 + 1];\n",
        "        const uint8_t b2 = qs[g * 4 + 2];\n",
        "        const uint8_t b3 = qs[g * 4 + 3];\n",
        "\n",
        "#pragma unroll\n",
        "        for (int i = 0; i < 16; ++i) {\n",
        "            const int idx_in_block = g * 16 + i;\n",
        "            if (idx_in_block >= block_elems) break;\n",
        "\n",
        "            const uint8_t pack = (i < 4) ? b0 : (i < 8) ? b1 : (i < 12) ? b2 : b3;\n",
        "            const uint8_t shift = static_cast<uint8_t>((i & 3) * 2);\n",
        "            const uint8_t q2 = static_cast<uint8_t>((pack >> shift) & 0x3u);\n",
        "\n",
        "            // Match CPU: val = dl * q2 - ml\n",
        "            const float val = dl * float(q2) - ml;\n",
        "\n",
        "            out[out_base + idx_in_block] = __float2half_rn(val);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "static __half* dequant_try_Q8_0(const uint8_t* bytes, size_t sz, size_t n_elems)\n",
        "{\n",
        "    const int blocks = int((n_elems + QK - 1) / QK);\n",
        "\n",
        "    // Q8_0 => blocks * (2 + 32)\n",
        "    size_t expect = size_t(blocks) * (2 + QK);\n",
        "    if (sz == expect) {\n",
        "        std::vector<int8_t>   hq(size_t(blocks) * QK);\n",
        "        std::vector<uint16_t> hs(blocks);\n",
        "        const uint8_t* p = bytes;\n",
        "        for (int b = 0; b < blocks; b++) {\n",
        "            uint16_t bits;\n",
        "            memcpy(&bits, p, 2);\n",
        "            p += 2;\n",
        "            hs[b] = bits;\n",
        "            memcpy(&hq[size_t(b) * QK], p, QK);\n",
        "            p += QK;\n",
        "        }\n",
        "        int8_t* dq = nullptr;\n",
        "        uint16_t* ds = nullptr;\n",
        "        __half* out = nullptr;\n",
        "        CUDA_OK(cudaMalloc(&dq, hq.size()));\n",
        "        CUDA_OK(cudaMalloc(&ds, hs.size() * sizeof(uint16_t)));\n",
        "        CUDA_OK(cudaMalloc(&out, n_elems * sizeof(__half)));\n",
        "        CUDA_OK(cudaMemcpy(dq, hq.data(), hq.size(), cudaMemcpyHostToDevice));\n",
        "        CUDA_OK(cudaMemcpy(ds, hs.data(), hs.size() * sizeof(uint16_t), cudaMemcpyHostToDevice));\n",
        "        int th = 256, bl = (blocks + th - 1) / th;\n",
        "        k_deq_q8 << <bl, th >> > (dq, ds, out, blocks);\n",
        "        CUDA_OK(cudaDeviceSynchronize());\n",
        "        cudaFree(dq);\n",
        "        cudaFree(ds);\n",
        "        return out;\n",
        "    }\n",
        "}\n",
        "// Try to dequantize a quant payload by size signature; return device FP16 (caller cudaFree) or nullptr\n",
        "static __half* dequant_try_Q2_K(const uint8_t* bytes, size_t sz, size_t n_elems)\n",
        "{\n",
        "    using namespace q2k_detail;\n",
        "\n",
        "    if (!bytes || n_elems == 0) return nullptr;\n",
        "\n",
        "    auto ceil_div = [](size_t a, size_t b) { return (a + b - 1) / b; };\n",
        "    const int    blocks = int(ceil_div(n_elems, size_t(QK_K)));\n",
        "    const size_t expect = size_t(blocks) * BYTES_PER_BLOCK;\n",
        "    if (sz != expect) {\n",
        "        // Not a raw Q2_K payload (or wrong size for QK_K=256).\n",
        "        return nullptr;\n",
        "    }\n",
        "\n",
        "    uint8_t* d_bytes = nullptr;\n",
        "    __half* d_out = nullptr;\n",
        "\n",
        "    CUDA_OK(cudaMalloc(&d_bytes, sz));\n",
        "    CUDA_OK(cudaMemcpy(d_bytes, bytes, sz, cudaMemcpyHostToDevice));\n",
        "    CUDA_OK(cudaMalloc(&d_out, n_elems * sizeof(__half)));\n",
        "\n",
        "    const int th = 256;\n",
        "    const int bl = (blocks + th - 1) / th;\n",
        "    k_deq_q2_k_to_f16_scales_qs_tail << <bl, th >> > (d_bytes, d_out, n_elems, blocks);\n",
        "    //CUDA_OK(cudaGetLastError());\n",
        "    CUDA_OK(cudaDeviceSynchronize());\n",
        "\n",
        "    cudaFree(d_bytes);\n",
        "    return d_out;  // device pointer; free with cudaFree\n",
        "}\n",
        "\n",
        "__global__ void k_f32_to_f16(__half* o, const float* x, size_t n)\n",
        "{\n",
        "    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n)\n",
        "        o[i] = __float2half(x[i]);\n",
        "}\n",
        "\n",
        "// =============== Main ===============\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    std::string pmp, pfp;\n",
        "    bool report = false, diffHL = false;\n",
        "\n",
        "    for (int i = 1; i < argc; i++)\n",
        "    {\n",
        "        std::string a = argv[i];\n",
        "        if (a == \"--mpgguf\" && i + 1 < argc)\n",
        "            pmp = argv[++i];\n",
        "        else if (a == \"--fp16\" && i + 1 < argc)\n",
        "            pfp = argv[++i];\n",
        "        else if (a == \"--report\")\n",
        "            report = true;\n",
        "        else if (a == \"--diff-high-low\")\n",
        "            diffHL = true;\n",
        "        else\n",
        "        {\n",
        "            std::cerr << \"Usage: --mpgguf <file> --fp16 <f16_or_f32.gguf> [--report] [--diff-high-low]\\n\";\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "    if (pmp.empty() || pfp.empty())\n",
        "    {\n",
        "        std::cerr << \"Missing --mpgguf or --fp16\\n\";\n",
        "        return 1;\n",
        "    }\n",
        "    auto split = [](const std::string& s, char delimiter) -> std::vector<std::string>\n",
        "    {\n",
        "        std::vector<std::string> tokens;\n",
        "        std::string token;\n",
        "        std::istringstream tokenStream(s);\n",
        "        while (std::getline(tokenStream, token, delimiter)) {\n",
        "            tokens.push_back(token);\n",
        "        }\n",
        "        return tokens;\n",
        "    };\n",
        "\n",
        "    auto pfps = split(pfp, ',');\n",
        "\n",
        "    MP mp;\n",
        "    if (!load_mp(pmp, mp)) {\n",
        "        std::cerr << \"bad mpgguf\\n\";\n",
        "        return 1;\n",
        "    }\n",
        "    std::vector<GG> ggs;\n",
        "    ggs.resize(pfps.size());\n",
        "\n",
        "    for (size_t i = 0; i < pfps.size(); i++)\n",
        "    {\n",
        "        if (!load_fp(i, pfps[i], ggs[i]))\n",
        "        {\n",
        "            std::cerr << \"bad gguf baseline\\n\";\n",
        "            return 1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Map baseline by name\n",
        "    std::unordered_map<std::string, GRec*> truth;\n",
        "    for (auto& gg : ggs)\n",
        "    {\n",
        "        for (auto& r : gg.recs)\n",
        "            truth[r.name] = &r;\n",
        "    }\n",
        "\n",
        "    auto N = [](const std::vector<uint64_t>& d) -> size_t {\n",
        "        return numel(d);\n",
        "        };\n",
        "    const size_t kMaxElems = size_t(1) << 36;  // Defensive ~64B elements\n",
        "\n",
        "    // Accumulators\n",
        "    double s_low = 0, n_low = 0, s_high = 0, n_high = 0, s_hl = 0, n_hl = 0;\n",
        "    float  m_low = 0, m_high = 0, m_hl = 0;\n",
        "    size_t validated_high = 0, validated_low = 0;\n",
        "\n",
        "    auto reduce = [&](const __half* A, const __half* B, size_t n, double& s, double& Nacc, float& m) {\n",
        "        std::vector<__half> ha(n), hb(n);\n",
        "        CUDA_OK(cudaMemcpy(ha.data(), A, n * sizeof(__half), cudaMemcpyDeviceToHost));\n",
        "        CUDA_OK(cudaMemcpy(hb.data(), B, n * sizeof(__half), cudaMemcpyDeviceToHost));\n",
        "        double ss = 0;\n",
        "        float  mx = 0;\n",
        "        for (size_t i = 0; i < n; i++) {\n",
        "            float d = __half2float(ha[i]) - __half2float(hb[i]);\n",
        "\n",
        "            if (std::isnan(d) || std::isinf(d))\n",
        "                continue;\n",
        "\n",
        "            ss += double(d) * double(d);\n",
        "            float ad = fabsf(d);\n",
        "            if (ad > mx) {\n",
        "                mx = ad;\n",
        "            }\n",
        "        }\n",
        "        s += ss;\n",
        "        Nacc += double(n);\n",
        "        if (mx > m) {\n",
        "            m = mx;\n",
        "        }\n",
        "        };\n",
        "\n",
        "    for (const auto& r : mp.recs)\n",
        "    {\n",
        "        auto it = truth.find(r.name);\n",
        "        if (it == truth.end())\n",
        "        {\n",
        "            if (report)\n",
        "                std::cerr << \"SKIP (missing in baseline): \" << r.name << \"\\n\";\n",
        "            continue;\n",
        "        }\n",
        "        const GRec& tr = *it->second;\n",
        "\n",
        "        if (tr.dims != r.dims)\n",
        "        {\n",
        "            if (report)\n",
        "                std::cerr << \"SKIP (shape mismatch): \" << r.name << \"\\n\";\n",
        "            continue;\n",
        "        }\n",
        "\n",
        "        size_t n = N(r.dims);\n",
        "        if (n == 0 || n > kMaxElems)\n",
        "        {\n",
        "            if (report)\n",
        "                std::cerr << \"SKIP (absurd n=\" << n << \"): \" << r.name << \"\\n\";\n",
        "            continue;\n",
        "        }\n",
        "\n",
        "        // Build FP16 truth (accept FP16 or FP32 tensor payloads)\n",
        "        __half* d_truth = nullptr;\n",
        "        //std::cout << tr.splitId << \",\" << tr.off << \"\\n\";\n",
        "        auto stream_data = readStreamData(ggs[tr.splitId].f, n * sizeof(float), tr.off);\n",
        "        const uint8_t* tb = stream_data.data();\n",
        "        //for (size_t i = 0; i < 100; i++)\n",
        "        //    std::cout << (int)stream_data[i] << \",\";\n",
        "        //std::cout << r.name << \"\\n\";\n",
        "\n",
        "        if (tr.g == 30)\n",
        "        {\n",
        "            CUDA_OK(cudaMalloc(&d_truth, tr.sz));\n",
        "            CUDA_OK(cudaMemcpy(d_truth, tb, tr.sz, cudaMemcpyHostToDevice));\n",
        "        }\n",
        "        else if (tr.g == 0)\n",
        "        {\n",
        "            float* df = nullptr;\n",
        "            CUDA_OK(cudaMalloc(&df, tr.sz));\n",
        "            CUDA_OK(cudaMemcpy(df, tb, tr.sz, cudaMemcpyHostToDevice));\n",
        "            CUDA_OK(cudaMalloc(&d_truth, n * sizeof(__half)));\n",
        "            int th = 256, bl = (int)((n + th - 1) / th);\n",
        "            k_f32_to_f16 << <bl, th >> > (d_truth, df, n);\n",
        "            CUDA_OK(cudaDeviceSynchronize());\n",
        "            cudaFree(df);\n",
        "        }\n",
        "        else\n",
        "        {\n",
        "            // Unknown baseline tensor type; zero it so it doesn't pollute aggregates\n",
        "            CUDA_OK(cudaMalloc(&d_truth, n * sizeof(__half)));\n",
        "            CUDA_OK(cudaMemset(d_truth, 0, n * sizeof(__half)));\n",
        "            if (report) {\n",
        "                std::cerr << \"WARN: baseline tensor \" << r.name << \" not FP16/FP32, treated as zeros\\n\";\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // HIGH (Q8_0 expected)\n",
        "        if (r.sz_high && in_range(r.off_high, r.sz_high, mp.data_sz) && r.g_high == 8)\n",
        "        {\n",
        "            auto data_high = readStreamData(mp.f, r.sz_high, mp.data_offset + r.off_high);\n",
        "            const uint8_t* hb = data_high.data();\n",
        "\n",
        "            __half* d_high = dequant_try_Q8_0(hb, (size_t)r.sz_high, n);\n",
        "            if (d_high)\n",
        "            {\n",
        "                reduce(d_high, d_truth, n, s_high, n_high, m_high);\n",
        "                cudaFree(d_high);\n",
        "                validated_high++;\n",
        "                std::cout << \"Tensor name for INT8_0: \" << validated_high << \", \" << r.name << \"\\n\";\n",
        "\n",
        "                if (validated_high > 100)\n",
        "                  break;\n",
        "            }\n",
        "            else if (report)\n",
        "            {\n",
        "                std::cerr << \"WARN: unrecognized HIGH payload for \" << r.name << \"\\n\";\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // LOW (legacy scalar 2-bit only; Q2_K/IQ2_* skipped)\n",
        "        if (r.sz_low && in_range(r.off_low, r.sz_low, mp.data_sz) && r.g_low == 10)\n",
        "        {\n",
        "            auto data_low = readStreamData(mp.f, r.sz_low, mp.data_offset + r.off_low);\n",
        "            const uint8_t* lb = data_low.data();\n",
        "            __half* d_low = dequant_try_Q2_K(lb, (size_t)r.sz_low, n);\n",
        "            if (d_low)\n",
        "            {\n",
        "                reduce(d_low, d_truth, n, s_low, n_low, m_low);\n",
        "                cudaFree(d_low);\n",
        "                validated_low++;\n",
        "                std::cout << \"Tensor name for INT2_K: \" << validated_low << \", \" << r.name << \"\\n\";\n",
        "            }\n",
        "            else if (report)\n",
        "                std::cerr << \"NOTE: skipping LOW dequant (likely Q2_K / IQ2_*): \" << r.name << \"\\n\";\n",
        "        }\n",
        "\n",
        "        cudaFree(d_truth);\n",
        "    }\n",
        "\n",
        "    auto outStats = [&](const char* tag, double s, double Nacc, float m, size_t ok) {\n",
        "        if (Nacc <= 0) {\n",
        "            std::cout << tag << \": N=0 (no tensors validated)\\n\";\n",
        "            return;\n",
        "        }\n",
        "        double mse = s / Nacc;\n",
        "        double rmse = std::sqrt(mse);\n",
        "        std::cout << tag << \": tensors=\" << ok << \"  N=\" << (uint64_t)Nacc << \"  MSE=\" << mse << \"  RMSE=\" << rmse\n",
        "            << \"  max =\" << m << \"\\n\";\n",
        "        };\n",
        "\n",
        "    outStats(\"HIGH(Q8_0) vs FP16\", s_high, n_high, m_high, validated_high);\n",
        "    outStats(\"LOW(2-bit)  vs FP16\", s_low, n_low, m_low, validated_low);\n",
        "    if (diffHL)\n",
        "        outStats(\"HIGH vs LOW\", s_hl, n_hl, m_hl, std::min(validated_high, validated_low));\n",
        "\n",
        "    CUDA_OK(cudaDeviceReset());\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXJDRRkQg-i8",
        "outputId": "88b4d4f9-d973-4539-e0a5-8eaee2a5f0d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing validate_mpgguf.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! cp \"/content/drive/MyDrive/Qwen3-1.7B-BF16.gguf\" .\n",
        "# ! cp \"/content/drive/MyDrive/qwen3-1.7-2.mpgguf\" ."
      ],
      "metadata": {
        "id": "_MQ1mT2klIlx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -o validate_mpgguf validate_mpgguf.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybAGfgZGhEbG",
        "outputId": "6b2b55cc-dcb0-44e2-ace6-aa20c7cf3a34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mvalidate_mpgguf.cu(695)\u001b[0m: \u001b[01;35mwarning\u001b[0m #940-D: missing return statement at end of non-void function \u001b[01m\"dequant_try_Q8_0\"\u001b[0m\n",
            "  }\n",
            "  ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mvalidate_mpgguf.cu(695)\u001b[0m: \u001b[01;35mwarning\u001b[0m #940-D: missing return statement at end of non-void function \u001b[01m\"dequant_try_Q8_0\"\u001b[0m\n",
            "  }\n",
            "  ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mvalidate_mpgguf.cu(144)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: function \u001b[01m\"rd_u32\"\u001b[0m was declared but never referenced\n",
            "  static inline uint32_t rd_u32(const uint8_t* p)\n",
            "                         ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mvalidate_mpgguf.cu(151)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: function \u001b[01m\"rd_u64\"\u001b[0m was declared but never referenced\n",
            "  static inline uint64_t rd_u64(const uint8_t* p)\n",
            "                         ^\n",
            "\n",
            "\u001b[01m\u001b[Kvalidate_mpgguf.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__half* dequant_try_Q8_0(const uint8_t*, size_t, size_t)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kvalidate_mpgguf.cu:695:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcontrol reaches end of non-void function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreturn-type\u0007-Wreturn-type\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  695 | \u001b[01;35m\u001b[K}\u001b[m\u001b[K\n",
            "      | \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./validate_mpgguf --mpgguf /content/drive/MyDrive/Qwen3-30B-A3B.mpgguf --fp16 /content/drive/MyDrive/Qwen3-30B-A3B-BF16-00001-of-00002.gguf,/content/drive/MyDrive/Qwen3-30B-A3B-BF16-00002-of-00002.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPoRaoNikXHm",
        "outputId": "d873c7e4-9e4b-4c51-d353-43197cc8ac61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor name for INT8_0: 1, output.weight\n",
            "Tensor name for INT8_0: 2, token_embd.weight\n",
            "Tensor name for INT2_K: 1, token_embd.weight\n",
            "Tensor name for INT8_0: 3, blk.0.attn_k.weight\n",
            "Tensor name for INT2_K: 2, blk.0.attn_k.weight\n",
            "Tensor name for INT8_0: 4, blk.0.attn_output.weight\n",
            "Tensor name for INT8_0: 5, blk.0.attn_q.weight\n",
            "Tensor name for INT2_K: 3, blk.0.attn_q.weight\n",
            "Tensor name for INT8_0: 6, blk.0.attn_v.weight\n",
            "Tensor name for INT8_0: 7, blk.0.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 8, blk.0.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 4, blk.0.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 9, blk.0.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 5, blk.0.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 10, blk.1.attn_k.weight\n",
            "Tensor name for INT2_K: 6, blk.1.attn_k.weight\n",
            "Tensor name for INT8_0: 11, blk.1.attn_output.weight\n",
            "Tensor name for INT8_0: 12, blk.1.attn_q.weight\n",
            "Tensor name for INT2_K: 7, blk.1.attn_q.weight\n",
            "Tensor name for INT8_0: 13, blk.1.attn_v.weight\n",
            "Tensor name for INT8_0: 14, blk.1.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 15, blk.1.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 8, blk.1.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 16, blk.1.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 9, blk.1.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 17, blk.2.attn_k.weight\n",
            "Tensor name for INT2_K: 10, blk.2.attn_k.weight\n",
            "Tensor name for INT8_0: 18, blk.2.attn_output.weight\n",
            "Tensor name for INT8_0: 19, blk.2.attn_q.weight\n",
            "Tensor name for INT2_K: 11, blk.2.attn_q.weight\n",
            "Tensor name for INT8_0: 20, blk.2.attn_v.weight\n",
            "Tensor name for INT8_0: 21, blk.2.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 22, blk.2.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 12, blk.2.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 23, blk.2.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 13, blk.2.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 24, blk.3.attn_k.weight\n",
            "Tensor name for INT2_K: 14, blk.3.attn_k.weight\n",
            "Tensor name for INT8_0: 25, blk.3.attn_output.weight\n",
            "Tensor name for INT8_0: 26, blk.3.attn_q.weight\n",
            "Tensor name for INT2_K: 15, blk.3.attn_q.weight\n",
            "Tensor name for INT8_0: 27, blk.3.attn_v.weight\n",
            "Tensor name for INT8_0: 28, blk.3.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 29, blk.3.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 16, blk.3.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 30, blk.3.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 17, blk.3.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 31, blk.4.attn_k.weight\n",
            "Tensor name for INT2_K: 18, blk.4.attn_k.weight\n",
            "Tensor name for INT8_0: 32, blk.4.attn_output.weight\n",
            "Tensor name for INT8_0: 33, blk.4.attn_q.weight\n",
            "Tensor name for INT2_K: 19, blk.4.attn_q.weight\n",
            "Tensor name for INT8_0: 34, blk.4.attn_v.weight\n",
            "Tensor name for INT8_0: 35, blk.4.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 36, blk.4.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 20, blk.4.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 37, blk.4.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 21, blk.4.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 38, blk.5.attn_k.weight\n",
            "Tensor name for INT2_K: 22, blk.5.attn_k.weight\n",
            "Tensor name for INT8_0: 39, blk.5.attn_output.weight\n",
            "Tensor name for INT8_0: 40, blk.5.attn_q.weight\n",
            "Tensor name for INT2_K: 23, blk.5.attn_q.weight\n",
            "Tensor name for INT8_0: 41, blk.5.attn_v.weight\n",
            "Tensor name for INT8_0: 42, blk.5.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 43, blk.5.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 24, blk.5.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 44, blk.5.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 25, blk.5.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 45, blk.6.attn_k.weight\n",
            "Tensor name for INT2_K: 26, blk.6.attn_k.weight\n",
            "Tensor name for INT8_0: 46, blk.6.attn_output.weight\n",
            "Tensor name for INT8_0: 47, blk.6.attn_q.weight\n",
            "Tensor name for INT2_K: 27, blk.6.attn_q.weight\n",
            "Tensor name for INT8_0: 48, blk.6.attn_v.weight\n",
            "Tensor name for INT8_0: 49, blk.6.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 50, blk.6.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 28, blk.6.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 51, blk.6.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 29, blk.6.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 52, blk.7.attn_k.weight\n",
            "Tensor name for INT2_K: 30, blk.7.attn_k.weight\n",
            "Tensor name for INT8_0: 53, blk.7.attn_output.weight\n",
            "Tensor name for INT8_0: 54, blk.7.attn_q.weight\n",
            "Tensor name for INT2_K: 31, blk.7.attn_q.weight\n",
            "Tensor name for INT8_0: 55, blk.7.attn_v.weight\n",
            "Tensor name for INT8_0: 56, blk.7.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 57, blk.7.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 32, blk.7.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 58, blk.7.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 33, blk.7.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 59, blk.8.attn_k.weight\n",
            "Tensor name for INT2_K: 34, blk.8.attn_k.weight\n",
            "Tensor name for INT8_0: 60, blk.8.attn_output.weight\n",
            "Tensor name for INT8_0: 61, blk.8.attn_q.weight\n",
            "Tensor name for INT2_K: 35, blk.8.attn_q.weight\n",
            "Tensor name for INT8_0: 62, blk.8.attn_v.weight\n",
            "Tensor name for INT8_0: 63, blk.8.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 64, blk.8.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 36, blk.8.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 65, blk.8.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 37, blk.8.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 66, blk.9.attn_k.weight\n",
            "Tensor name for INT2_K: 38, blk.9.attn_k.weight\n",
            "Tensor name for INT8_0: 67, blk.9.attn_output.weight\n",
            "Tensor name for INT8_0: 68, blk.9.attn_q.weight\n",
            "Tensor name for INT2_K: 39, blk.9.attn_q.weight\n",
            "Tensor name for INT8_0: 69, blk.9.attn_v.weight\n",
            "Tensor name for INT8_0: 70, blk.9.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 71, blk.9.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 40, blk.9.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 72, blk.9.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 41, blk.9.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 73, blk.10.attn_k.weight\n",
            "Tensor name for INT2_K: 42, blk.10.attn_k.weight\n",
            "Tensor name for INT8_0: 74, blk.10.attn_output.weight\n",
            "Tensor name for INT8_0: 75, blk.10.attn_q.weight\n",
            "Tensor name for INT2_K: 43, blk.10.attn_q.weight\n",
            "Tensor name for INT8_0: 76, blk.10.attn_v.weight\n",
            "Tensor name for INT8_0: 77, blk.10.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 78, blk.10.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 44, blk.10.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 79, blk.10.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 45, blk.10.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 80, blk.11.attn_k.weight\n",
            "Tensor name for INT2_K: 46, blk.11.attn_k.weight\n",
            "Tensor name for INT8_0: 81, blk.11.attn_output.weight\n",
            "Tensor name for INT8_0: 82, blk.11.attn_q.weight\n",
            "Tensor name for INT2_K: 47, blk.11.attn_q.weight\n",
            "Tensor name for INT8_0: 83, blk.11.attn_v.weight\n",
            "Tensor name for INT8_0: 84, blk.11.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 85, blk.11.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 48, blk.11.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 86, blk.11.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 49, blk.11.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 87, blk.12.attn_k.weight\n",
            "Tensor name for INT2_K: 50, blk.12.attn_k.weight\n",
            "Tensor name for INT8_0: 88, blk.12.attn_output.weight\n",
            "Tensor name for INT8_0: 89, blk.12.attn_q.weight\n",
            "Tensor name for INT2_K: 51, blk.12.attn_q.weight\n",
            "Tensor name for INT8_0: 90, blk.12.attn_v.weight\n",
            "Tensor name for INT8_0: 91, blk.12.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 92, blk.12.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 52, blk.12.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 93, blk.12.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 53, blk.12.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 94, blk.13.attn_k.weight\n",
            "Tensor name for INT2_K: 54, blk.13.attn_k.weight\n",
            "Tensor name for INT8_0: 95, blk.13.attn_output.weight\n",
            "Tensor name for INT8_0: 96, blk.13.attn_q.weight\n",
            "Tensor name for INT2_K: 55, blk.13.attn_q.weight\n",
            "Tensor name for INT8_0: 97, blk.13.attn_v.weight\n",
            "Tensor name for INT8_0: 98, blk.13.ffn_down_exps.weight\n",
            "Tensor name for INT8_0: 99, blk.13.ffn_gate_exps.weight\n",
            "Tensor name for INT2_K: 56, blk.13.ffn_gate_exps.weight\n",
            "Tensor name for INT8_0: 100, blk.13.ffn_up_exps.weight\n",
            "Tensor name for INT2_K: 57, blk.13.ffn_up_exps.weight\n",
            "Tensor name for INT8_0: 101, blk.14.attn_k.weight\n",
            "HIGH(Q8_0) vs FP16: tensors=101  N=9343336448  MSE=1.21974  RMSE=1.10442  max =1.99805\n",
            "LOW(2-bit)  vs FP16: tensors=57  N=6080430080  MSE=1.21416  RMSE=1.10189  max =1.96973\n"
          ]
        }
      ]
    }
  ]
}